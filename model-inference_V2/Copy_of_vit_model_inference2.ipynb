{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/SKD151105/Skin-Cancer-Classification/blob/main/model-inference_V2/vit_model_inference.ipynb",
      "authorship_tag": "ABX9TyNtXQo+B84KxYsVadZEStKC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SKD151105/Skin-Cancer-Classification/blob/main/model-inference_V2/Copy_of_vit_model_inference2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Step 1: Imports\n",
        "# ======================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import ViTForImageClassification, ViTFeatureExtractor, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# ======================================================\n",
        "# Step 2: Load and preprocess data\n",
        "# ======================================================\n",
        "data = pd.read_csv('/content/drive/MyDrive/mini_proj_data/HAM10000/hmnist_28_28_RGB.csv')\n",
        "X = data.drop(columns=['label']).values\n",
        "y = data['label'].values"
      ],
      "metadata": {
        "id": "gXZ3wL0LSuWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "v5VYeVz-T6On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "xT7l38noT6Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape flattened pixels â†’ 28x28x3\n",
        "X = X.reshape(-1, 28, 28, 3).astype(np.uint8)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# ======================================================\n",
        "# Step 3: Prepare HuggingFace feature extractor\n",
        "# ======================================================\n",
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "\n",
        "# ======================================================\n",
        "# Step 4: Create Custom Dataset class\n",
        "# ======================================================\n",
        "class HMNISTDataset(Dataset):\n",
        "    def __init__(self, images, labels, extractor):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.extractor = extractor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.fromarray(self.images[idx])\n",
        "        inputs = self.extractor(images=img, return_tensors=\"pt\")\n",
        "        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n",
        "        inputs['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return inputs\n",
        "\n",
        "train_dataset = HMNISTDataset(X_train, y_train, feature_extractor)\n",
        "val_dataset = HMNISTDataset(X_val, y_val, feature_extractor)\n"
      ],
      "metadata": {
        "id": "MPHGmTcnT6Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Step 5: Load ViT model for classification\n",
        "# ======================================================\n",
        "num_classes = len(np.unique(y))\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    'google/vit-base-patch16-224-in21k',\n",
        "    num_labels=num_classes\n",
        ")"
      ],
      "metadata": {
        "id": "or8evUlUT6FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Step 7: Define metric computation\n",
        "# ======================================================\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc}\n",
        "\n",
        "# ======================================================\n",
        "# Step 8: Train the model\n",
        "# ======================================================\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./vit_output',\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./vit_logs',\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\"  # ðŸš« disables wandb / tensorboard logging cleanly\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n"
      ],
      "metadata": {
        "id": "9MNIt77lT6Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "YDp3WebmXAPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Step 9: Evaluate model\n",
        "# ======================================================\n",
        "preds = trainer.predict(val_dataset)\n",
        "y_pred = np.argmax(preds.predictions, axis=1)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(classification_report(y_val, y_pred))\n",
        "\n",
        "# ======================================================\n",
        "# Step 10: Inference on all data & Save to CSV\n",
        "# ======================================================\n",
        "inference_dataset = HMNISTDataset(X, y, feature_extractor)\n",
        "inference_loader = DataLoader(inference_dataset, batch_size=16)\n",
        "\n",
        "model.eval()\n",
        "results = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, batch in enumerate(inference_loader):\n",
        "        inputs = {k: v.to(model.device) for k, v in batch.items() if k != 'labels'}\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        preds = probs.argmax(dim=-1).cpu().numpy()\n",
        "        confs = probs.max(dim=-1).values.cpu().numpy()\n",
        "\n",
        "        for j in range(len(preds)):\n",
        "            results.append({\n",
        "                'image_id': i * 16 + j,\n",
        "                'true_label': int(batch['labels'][j]),\n",
        "                'predicted_label': int(preds[j]),\n",
        "                'confidence': float(confs[j])\n",
        "            })\n",
        "\n",
        "# Save results to CSV\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('/content/drive/MyDrive/mini_proj_data/vit_inference_results.csv', index=False)\n",
        "print(\"Inference results saved to vit_inference_results.csv âœ…\")"
      ],
      "metadata": {
        "id": "1guCs3mqVvfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/vit_output /content/drive/MyDrive/mini_proj_data/\n"
      ],
      "metadata": {
        "id": "ftZXNBopgpAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XsZFzQNWgpn9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}