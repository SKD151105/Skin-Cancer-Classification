{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sop81pPB5ORf",
        "outputId": "d2e53d22-f67e-4375-f030-890361e272b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# ---------------------------\n",
        "# Block 1 — Mount Drive & copy images to local Colab storage (fast I/O)\n",
        "# ---------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# # copy images folder from Drive to Colab local disk (adjust source path if different)\n",
        "# !cp -r /content/drive/MyDrive/mini_proj_data/images /content/images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "us9r-vGoHnr4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>image_path</th>\n",
              "      <th>label_id</th>\n",
              "      <th>is_malignant</th>\n",
              "      <th>clean_path</th>\n",
              "      <th>variant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>clean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>clean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>clean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>clean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>clean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10010</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033084</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>clean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10011</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033550</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>clean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10012</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033536</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>clean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10013</th>\n",
              "      <td>HAM_0000239</td>\n",
              "      <td>ISIC_0032854</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>face</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>clean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10014</th>\n",
              "      <td>HAM_0003521</td>\n",
              "      <td>ISIC_0032258</td>\n",
              "      <td>mel</td>\n",
              "      <td>histo</td>\n",
              "      <td>70.0</td>\n",
              "      <td>female</td>\n",
              "      <td>back</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>clean</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10015 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         lesion_id      image_id     dx dx_type   age     sex localization  \\\n",
              "0      HAM_0000118  ISIC_0027419    bkl   histo  80.0    male        scalp   \n",
              "1      HAM_0000118  ISIC_0025030    bkl   histo  80.0    male        scalp   \n",
              "2      HAM_0002730  ISIC_0026769    bkl   histo  80.0    male        scalp   \n",
              "3      HAM_0002730  ISIC_0025661    bkl   histo  80.0    male        scalp   \n",
              "4      HAM_0001466  ISIC_0031633    bkl   histo  75.0    male          ear   \n",
              "...            ...           ...    ...     ...   ...     ...          ...   \n",
              "10010  HAM_0002867  ISIC_0033084  akiec   histo  40.0    male      abdomen   \n",
              "10011  HAM_0002867  ISIC_0033550  akiec   histo  40.0    male      abdomen   \n",
              "10012  HAM_0002867  ISIC_0033536  akiec   histo  40.0    male      abdomen   \n",
              "10013  HAM_0000239  ISIC_0032854  akiec   histo  80.0    male         face   \n",
              "10014  HAM_0003521  ISIC_0032258    mel   histo  70.0  female         back   \n",
              "\n",
              "                                              image_path  label_id  \\\n",
              "0      C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...         2   \n",
              "1      C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...         2   \n",
              "2      C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...         2   \n",
              "3      C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...         2   \n",
              "4      C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...         2   \n",
              "...                                                  ...       ...   \n",
              "10010  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...         0   \n",
              "10011  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...         0   \n",
              "10012  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...         0   \n",
              "10013  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...         0   \n",
              "10014  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...         4   \n",
              "\n",
              "       is_malignant                                         clean_path variant  \n",
              "0                 0  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...   clean  \n",
              "1                 0  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...   clean  \n",
              "2                 0  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...   clean  \n",
              "3                 0  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...   clean  \n",
              "4                 0  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...   clean  \n",
              "...             ...                                                ...     ...  \n",
              "10010             1  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...   clean  \n",
              "10011             1  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...   clean  \n",
              "10012             1  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...   clean  \n",
              "10013             1  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...   clean  \n",
              "10014             1  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...   clean  \n",
              "\n",
              "[10015 rows x 12 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#For Local Machine(Ignore for colab)\n",
        "df=pd.read_csv(r'C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data\\processed_data.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "Sgf6FuVdHkjh",
        "outputId": "88f72a17-2a54-41a1-bd9e-50220051cb89"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/mini_proj_data/processed_data.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/content/drive/MyDrive/mini_proj_data/processed_data.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ompat\\OneDrive\\Desktop\\Skin-Cancer-Classification\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ompat\\OneDrive\\Desktop\\Skin-Cancer-Classification\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ompat\\OneDrive\\Desktop\\Skin-Cancer-Classification\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ompat\\OneDrive\\Desktop\\Skin-Cancer-Classification\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ompat\\OneDrive\\Desktop\\Skin-Cancer-Classification\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/drive/MyDrive/mini_proj_data/processed_data.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/mini_proj_data/processed_data.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFca1CzSHpBI",
        "outputId": "080f71ee-55ac-44c7-830e-d362fdbdaee9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['lesion_id', 'image_id', 'dx', 'dx_type', 'age', 'sex', 'localization',\n",
              "       'image_path', 'label_id', 'is_malignant', 'clean_path', 'variant'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "091ZuLiV3nTJ"
      },
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Block 2 — Load CSV, prepare metadata, labels and image paths; create train/val/test splits\n",
        "# ---------------------------\n",
        "\n",
        "\n",
        "# Keep only useful cols\n",
        "# Keep lesion_id to avoid leakage\n",
        "y = df['label_id'].values\n",
        "df = df[['lesion_id','image_path','clean_path','age','sex','localization',\n",
        "         'dx_type','is_malignant','variant']].copy()\n",
        "\n",
        "# --- Handle missing values safely ---\n",
        "df['age'] = pd.to_numeric(df['age'], errors='coerce')   # force non-numeric → NaN\n",
        "df['age'] = df['age'].fillna(df['age'].median())        # fill NaN with median\n",
        "\n",
        "# Clean up sex values (some datasets have 'unknown' or nan)\n",
        "df['sex'] = df['sex'].str.lower().replace({'nan': np.nan, 'unknown': np.nan, '': np.nan})\n",
        "df['sex'] = df['sex'].map({'male':0,'female':1})\n",
        "df['sex'] = df['sex'].fillna(-1).astype('float32')      # -1 = unknown, keeps row\n",
        "\n",
        "# Drop rows where image path is missing\n",
        "df = df.dropna(subset=['clean_path','is_malignant'])\n",
        "\n",
        "# One-hot encode categorical vars (fills missing with \"unknown\")\n",
        "for col in ['localization','dx_type']:\n",
        "    df[col] = df[col].fillna('unknown')\n",
        "df = pd.get_dummies(df, columns=['localization','dx_type','variant'], drop_first=False)\n",
        "\n",
        "# Scale age safely/\n",
        "scaler = StandardScaler()\n",
        "df['age_scaled'] = scaler.fit_transform(df[['age']]).astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "GPzkJivV4wiv",
        "outputId": "faacc2b0-6641-4a04-9d9d-d9046c4412c8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>clean_path</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>is_malignant</th>\n",
              "      <th>localization_abdomen</th>\n",
              "      <th>localization_acral</th>\n",
              "      <th>localization_back</th>\n",
              "      <th>localization_chest</th>\n",
              "      <th>...</th>\n",
              "      <th>localization_scalp</th>\n",
              "      <th>localization_trunk</th>\n",
              "      <th>localization_unknown</th>\n",
              "      <th>localization_upper extremity</th>\n",
              "      <th>dx_type_confocal</th>\n",
              "      <th>dx_type_consensus</th>\n",
              "      <th>dx_type_follow_up</th>\n",
              "      <th>dx_type_histo</th>\n",
              "      <th>variant_clean</th>\n",
              "      <th>age_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1.663522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1.663522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1.663522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1.663522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1.368014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10010</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.700545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10011</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.700545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10012</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>-0.700545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10013</th>\n",
              "      <td>HAM_0000239</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1.663522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10014</th>\n",
              "      <td>HAM_0003521</td>\n",
              "      <td>C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...</td>\n",
              "      <td>C:/Users/ompat/OneDrive/Desktop/mini_proj_data...</td>\n",
              "      <td>70.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1.072505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10015 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         lesion_id                                         image_path  \\\n",
              "0      HAM_0000118  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...   \n",
              "1      HAM_0000118  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...   \n",
              "2      HAM_0002730  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...   \n",
              "3      HAM_0002730  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...   \n",
              "4      HAM_0001466  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...   \n",
              "...            ...                                                ...   \n",
              "10010  HAM_0002867  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...   \n",
              "10011  HAM_0002867  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...   \n",
              "10012  HAM_0002867  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...   \n",
              "10013  HAM_0000239  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...   \n",
              "10014  HAM_0003521  C:\\Users\\ompat\\OneDrive\\Desktop\\mini_proj_data...   \n",
              "\n",
              "                                              clean_path   age  sex  \\\n",
              "0      C:/Users/ompat/OneDrive/Desktop/mini_proj_data...  80.0  0.0   \n",
              "1      C:/Users/ompat/OneDrive/Desktop/mini_proj_data...  80.0  0.0   \n",
              "2      C:/Users/ompat/OneDrive/Desktop/mini_proj_data...  80.0  0.0   \n",
              "3      C:/Users/ompat/OneDrive/Desktop/mini_proj_data...  80.0  0.0   \n",
              "4      C:/Users/ompat/OneDrive/Desktop/mini_proj_data...  75.0  0.0   \n",
              "...                                                  ...   ...  ...   \n",
              "10010  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...  40.0  0.0   \n",
              "10011  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...  40.0  0.0   \n",
              "10012  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...  40.0  0.0   \n",
              "10013  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...  80.0  0.0   \n",
              "10014  C:/Users/ompat/OneDrive/Desktop/mini_proj_data...  70.0  1.0   \n",
              "\n",
              "       is_malignant  localization_abdomen  localization_acral  \\\n",
              "0                 0                 False               False   \n",
              "1                 0                 False               False   \n",
              "2                 0                 False               False   \n",
              "3                 0                 False               False   \n",
              "4                 0                 False               False   \n",
              "...             ...                   ...                 ...   \n",
              "10010             1                  True               False   \n",
              "10011             1                  True               False   \n",
              "10012             1                  True               False   \n",
              "10013             1                 False               False   \n",
              "10014             1                 False               False   \n",
              "\n",
              "       localization_back  localization_chest  ...  localization_scalp  \\\n",
              "0                  False               False  ...                True   \n",
              "1                  False               False  ...                True   \n",
              "2                  False               False  ...                True   \n",
              "3                  False               False  ...                True   \n",
              "4                  False               False  ...               False   \n",
              "...                  ...                 ...  ...                 ...   \n",
              "10010              False               False  ...               False   \n",
              "10011              False               False  ...               False   \n",
              "10012              False               False  ...               False   \n",
              "10013              False               False  ...               False   \n",
              "10014               True               False  ...               False   \n",
              "\n",
              "       localization_trunk  localization_unknown  localization_upper extremity  \\\n",
              "0                   False                 False                         False   \n",
              "1                   False                 False                         False   \n",
              "2                   False                 False                         False   \n",
              "3                   False                 False                         False   \n",
              "4                   False                 False                         False   \n",
              "...                   ...                   ...                           ...   \n",
              "10010               False                 False                         False   \n",
              "10011               False                 False                         False   \n",
              "10012               False                 False                         False   \n",
              "10013               False                 False                         False   \n",
              "10014               False                 False                         False   \n",
              "\n",
              "       dx_type_confocal  dx_type_consensus  dx_type_follow_up  dx_type_histo  \\\n",
              "0                 False              False              False           True   \n",
              "1                 False              False              False           True   \n",
              "2                 False              False              False           True   \n",
              "3                 False              False              False           True   \n",
              "4                 False              False              False           True   \n",
              "...                 ...                ...                ...            ...   \n",
              "10010             False              False              False           True   \n",
              "10011             False              False              False           True   \n",
              "10012             False              False              False           True   \n",
              "10013             False              False              False           True   \n",
              "10014             False              False              False           True   \n",
              "\n",
              "       variant_clean  age_scaled  \n",
              "0               True    1.663522  \n",
              "1               True    1.663522  \n",
              "2               True    1.663522  \n",
              "3               True    1.663522  \n",
              "4               True    1.368014  \n",
              "...              ...         ...  \n",
              "10010           True   -0.700545  \n",
              "10011           True   -0.700545  \n",
              "10012           True   -0.700545  \n",
              "10013           True    1.663522  \n",
              "10014           True    1.072505  \n",
              "\n",
              "[10015 rows x 27 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQKzY4NT6q_O",
        "outputId": "c745af70-6019-4645-b19f-bd4106e49de2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 0, 0, 4], shape=(10015,))"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUgxaVi98-E8",
        "outputId": "f73838cc-603d-4334-9860-202aeec3850f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.6635225 ,  0.        ,  0.        , ...,  0.        ,\n",
              "         1.        ,  1.        ],\n",
              "       [ 1.6635225 ,  0.        ,  0.        , ...,  0.        ,\n",
              "         1.        ,  1.        ],\n",
              "       [ 1.6635225 ,  0.        ,  0.        , ...,  0.        ,\n",
              "         1.        ,  1.        ],\n",
              "       ...,\n",
              "       [-0.70054543,  0.        ,  1.        , ...,  0.        ,\n",
              "         1.        ,  1.        ],\n",
              "       [ 1.6635225 ,  0.        ,  0.        , ...,  0.        ,\n",
              "         1.        ,  1.        ],\n",
              "       [ 1.0725055 ,  1.        ,  0.        , ...,  0.        ,\n",
              "         1.        ,  1.        ]], shape=(10015, 22), dtype=float32)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Metadata features\n",
        "feature_cols = ['age_scaled','sex'] + [c for c in df.columns if c.startswith('localization_')\n",
        "                                        or c.startswith('dx_type_')\n",
        "                                        or c.startswith('variant_')]\n",
        "X_meta = df[feature_cols].values.astype('float32')\n",
        "\n",
        "X_meta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS2oyepq9QNT",
        "outputId": "79138e67-238e-42e1-f4fe-1b9830f7fdf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10015, 22)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_meta.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RMabJO2n6MU-"
      },
      "outputs": [],
      "source": [
        "# # Collect metadata features\n",
        "# # feature_cols = ['age_scaled','sex'] + [c for c in df.columns if c.startswith('localization_') or c.startswith('dx_type_') or c.startswith('variant_')]\n",
        "# X_meta_all = df[feature_cols].values.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKo3NS3U5YHI",
        "outputId": "3c407914-de17-4251-9f30-ffa5152f2cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lesion classes: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc'] → 7\n",
            "✅ Dataset sizes: train=14004, val=2994, test=3032, num_classes=7\n"
          ]
        }
      ],
      "source": [
        "# # ---------------------------\n",
        "# # Block 2 — Load CSV, prepare metadata, labels and image paths; create train/val/test splits\n",
        "# # ---------------------------\n",
        "\n",
        "\n",
        "# # Keep only useful cols\n",
        "# # Keep lesion_id to avoid leakage\n",
        "# df = df[['lesion_id','image_path','clean_path','age','sex','localization',\n",
        "#          'dx_type','is_malignant','dx','variant']].copy()\n",
        "\n",
        "# # --- Handle missing values safely ---\n",
        "# df['age'] = pd.to_numeric(df['age'], errors='coerce')   # force non-numeric → NaN\n",
        "# df['age'] = df['age'].fillna(df['age'].median())        # fill NaN with median\n",
        "\n",
        "# # Clean up sex values (some datasets have 'unknown' or nan)\n",
        "# df['sex'] = df['sex'].str.lower().replace({'nan': np.nan, 'unknown': np.nan, '': np.nan})\n",
        "# df['sex'] = df['sex'].map({'male':0,'female':1})\n",
        "# df['sex'] = df['sex'].fillna(-1).astype('float32')      # -1 = unknown, keeps row\n",
        "\n",
        "# # Drop rows where image path is missing\n",
        "# df = df.dropna(subset=['clean_path','is_malignant'])\n",
        "\n",
        "# # One-hot encode categorical vars (fills missing with \"unknown\")\n",
        "# for col in ['localization','dx_type']:\n",
        "#     df[col] = df[col].fillna('unknown')\n",
        "# df = pd.get_dummies(df, columns=['localization','dx_type','variant'], drop_first=False)\n",
        "\n",
        "# # Scale age safely\n",
        "# scaler = StandardScaler()\n",
        "# df['age_scaled'] = scaler.fit_transform(df[['age']]).astype('float32')\n",
        "\n",
        "# # Collect metadata features\n",
        "# feature_cols = ['age_scaled','sex'] + [c for c in df.columns if c.startswith('localization_') or c.startswith('dx_type_') or c.startswith('variant_')]\n",
        "# X_meta_all = df[feature_cols].values.astype('float32')\n",
        "\n",
        "# # Labels\n",
        "# # Encode lesion type (dx) as categorical\n",
        "# df['dx'] = df['dx'].astype('category')\n",
        "# y_all = df['dx'].cat.codes.values   # integer labels\n",
        "# class_names = list(df['dx'].cat.categories)  # store mapping\n",
        "\n",
        "# num_classes = df['dx'].nunique()\n",
        "# print(\"Lesion classes:\", class_names, \"→\", num_classes)\n",
        "\n",
        "# # Replace Drive paths with local paths\n",
        "# def map_to_local(path):\n",
        "#     return str(path).replace('/content/drive/MyDrive/mini_proj_data/images', '/content/images')\n",
        "\n",
        "# image_paths_all = df['clean_path'].astype(str).apply(map_to_local).values\n",
        "\n",
        "# # Sanity check missing images → drop if missing\n",
        "# missing = [p for p in image_paths_all if not os.path.exists(p)]\n",
        "# if len(missing) > 0:\n",
        "#     print(f\"⚠️ {len(missing)} missing images will be dropped (showing first 5):\", missing[:5])\n",
        "#     keep_mask = np.array([p not in missing for p in image_paths_all])\n",
        "#     image_paths_all = image_paths_all[keep_mask]\n",
        "#     X_meta_all = X_meta_all[keep_mask]\n",
        "#     y_all = y_all[keep_mask]\n",
        "\n",
        "# # # Train/val/test split (stratified)\n",
        "# # train_idx, temp_idx = train_test_split(np.arange(len(y_all)), test_size=0.3, stratify=y_all, random_state=42)\n",
        "# # val_idx, test_idx   = train_test_split(temp_idx, test_size=0.5, stratify=y_all[temp_idx], random_state=42)\n",
        "\n",
        "# # train_paths, val_paths, test_paths = image_paths_all[train_idx], image_paths_all[val_idx], image_paths_all[test_idx]\n",
        "# # train_meta,  val_meta,  test_meta  = X_meta_all[train_idx], X_meta_all[val_idx], X_meta_all[test_idx]\n",
        "# # train_labels, val_labels, test_labels = y_all[train_idx], y_all[val_idx], y_all[test_idx]\n",
        "\n",
        "# # # Label typing\n",
        "# # num_classes = len(np.unique(y_all))\n",
        "# # # if num_classes == 2:\n",
        "# # #     # Binary classification → float32 labels\n",
        "# # #     train_labels_cast = train_labels.astype('float32')\n",
        "# # #     val_labels_cast   = val_labels.astype('float32')\n",
        "# # #     test_labels_cast  = test_labels.astype('float32')\n",
        "# # #     chosen_loss = 'binary_crossentropy'\n",
        "# # # else:\n",
        "# #     # Multi-class → one-hot\n",
        "# # train_labels_cast = to_categorical(train_labels, num_classes=num_classes).astype('float32')\n",
        "# # val_labels_cast   = to_categorical(val_labels, num_classes=num_classes).astype('float32')\n",
        "# # test_labels_cast  = to_categorical(test_labels, num_classes=num_classes).astype('float32')\n",
        "# # chosen_loss = 'categorical_crossentropy'\n",
        "\n",
        "# # print(f\"✅ Dataset sizes: train={len(train_paths)}, val={len(val_paths)}, test={len(test_paths)}, num_classes={num_classes}\")\n",
        "\n",
        "# # ---------------------------\n",
        "# # 🚨 Lesion-level splitting\n",
        "# # ---------------------------\n",
        "# unique_ids = df['lesion_id'].unique()\n",
        "# id_to_label = df.drop_duplicates('lesion_id')[['lesion_id','dx']]\n",
        "\n",
        "# train_ids, temp_ids = train_test_split(\n",
        "#     id_to_label['lesion_id'],\n",
        "#     test_size=0.3,\n",
        "#     stratify=id_to_label['dx'],\n",
        "#     random_state=42\n",
        "# )\n",
        "# val_ids, test_ids = train_test_split(\n",
        "#     temp_ids,\n",
        "#     test_size=0.5,\n",
        "#     stratify=id_to_label[id_to_label['lesion_id'].isin(temp_ids)]['dx'],\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "# train_df = df[df['lesion_id'].isin(train_ids)].reset_index(drop=True)\n",
        "# val_df   = df[df['lesion_id'].isin(val_ids)].reset_index(drop=True)\n",
        "# test_df  = df[df['lesion_id'].isin(test_ids)].reset_index(drop=True)\n",
        "\n",
        "# # Extract arrays\n",
        "# train_paths, val_paths, test_paths = train_df['image_path'].values, val_df['image_path'].values, test_df['image_path'].values\n",
        "# train_meta,  val_meta,  test_meta  = train_df[feature_cols].values, val_df[feature_cols].values, test_df[feature_cols].values\n",
        "# train_labels, val_labels, test_labels = train_df['dx'].cat.codes.values, val_df['dx'].cat.codes.values, test_df['dx'].cat.codes.values\n",
        "\n",
        "# # One-hot encode labels\n",
        "# train_labels_cast = to_categorical(train_labels, num_classes=num_classes).astype('float32')\n",
        "# val_labels_cast   = to_categorical(val_labels, num_classes=num_classes).astype('float32')\n",
        "# test_labels_cast  = to_categorical(test_labels, num_classes=num_classes).astype('float32')\n",
        "# chosen_loss = 'categorical_crossentropy'\n",
        "\n",
        "# print(f\"✅ Dataset sizes: train={len(train_paths)}, val={len(val_paths)}, test={len(test_paths)}, num_classes={num_classes}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df['image_path']   # paths to images\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train + validation and test split\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y, test_size=0.1, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Train and validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.1, stratify=y_train_val, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "rKeTUTI27WcF",
        "outputId": "77ccfd02-4582-4b27-abf2-eb8f2dff4c6e"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_and_preprocess_image(path, target_size=(224,224)):\n",
        "    img = cv2.imread(path)                      # read image\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
        "    img = cv2.resize(img, target_size)\n",
        "    img = img / 255.0                           # normalize to [0,1]\n",
        "    return img.astype('float32')\n",
        "\n",
        "# --- Load datasets ---\n",
        "X_train_images = np.array([load_and_preprocess_image(p) for p in X_train])\n",
        "X_val_images   = np.array([load_and_preprocess_image(p) for p in X_val])\n",
        "X_test_images  = np.array([load_and_preprocess_image(p) for p in X_test])\n",
        "\n",
        "# --- Standardization step (per-channel) ---\n",
        "mean = np.mean(X_train_images, axis=(0,1,2), keepdims=True)\n",
        "std  = np.std(X_train_images, axis=(0,1,2), keepdims=True)\n",
        "\n",
        "X_train_images = (X_train_images - mean) / (std + 1e-7)\n",
        "X_val_images   = (X_val_images   - mean) / (std + 1e-7)\n",
        "X_test_images  = (X_test_images  - mean) / (std + 1e-7)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[2.327171 , 1.6704758, 1.6318468],\n",
              "         [2.3464856, 1.6704758, 1.6318468],\n",
              "         [2.327171 , 1.6511613, 1.6125321],\n",
              "         ...,\n",
              "         [2.810035 , 2.3464856, 2.3464856],\n",
              "         [2.8486643, 2.288542 , 2.327171 ],\n",
              "         [2.8872933, 2.327171 , 2.3658001]],\n",
              "\n",
              "        [[2.3851147, 1.709105 , 1.6704758],\n",
              "         [2.3658001, 1.709105 , 1.6704758],\n",
              "         [2.3658001, 1.6897904, 1.6511613],\n",
              "         ...,\n",
              "         [2.8679788, 2.4044294, 2.4044294],\n",
              "         [2.945237 , 2.3658001, 2.4044294],\n",
              "         [2.8872933, 2.327171 , 2.3658001]],\n",
              "\n",
              "        [[2.288542 , 1.709105 , 1.6318468],\n",
              "         [2.3658001, 1.6897904, 1.6511613],\n",
              "         [2.3851147, 1.709105 , 1.6704758],\n",
              "         ...,\n",
              "         [2.8679788, 2.3851147, 2.4044294],\n",
              "         [2.8872933, 2.3851147, 2.4044294],\n",
              "         [2.8486643, 2.327171 , 2.3851147]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[2.288542 , 1.5932176, 1.5932176],\n",
              "         [2.3078566, 1.6125321, 1.5932176],\n",
              "         [2.3078566, 1.6318468, 1.5739031],\n",
              "         ...,\n",
              "         [2.9259224, 2.4044294, 2.501002 ],\n",
              "         [2.8872933, 2.4044294, 2.4816875],\n",
              "         [2.9066079, 2.4430585, 2.501002 ]],\n",
              "\n",
              "        [[2.288542 , 1.6125321, 1.5739031],\n",
              "         [2.3078566, 1.6318468, 1.5739031],\n",
              "         [2.288542 , 1.6125321, 1.5739031],\n",
              "         ...,\n",
              "         [2.8872933, 2.3658001, 2.462373 ],\n",
              "         [2.8872933, 2.3658001, 2.4816875],\n",
              "         [2.8293498, 2.2692275, 2.3851147]],\n",
              "\n",
              "        [[2.2692275, 1.5932176, 1.5545884],\n",
              "         [2.3078566, 1.6511613, 1.6125321],\n",
              "         [2.3078566, 1.6318468, 1.6125321],\n",
              "         ...,\n",
              "         [2.8872933, 2.3658001, 2.462373 ],\n",
              "         [2.8293498, 2.3464856, 2.3851147],\n",
              "         [2.8486643, 2.3464856, 2.4044294]]],\n",
              "\n",
              "\n",
              "       [[[3.2349555, 2.674833 , 3.0418098],\n",
              "         [3.1963263, 2.7134624, 3.0224953],\n",
              "         [3.3122137, 2.7520914, 3.0611243],\n",
              "         ...,\n",
              "         [3.0611243, 2.6168895, 3.0224953],\n",
              "         [3.1190681, 2.636204 , 3.0224953],\n",
              "         [3.0611243, 2.6555185, 3.0418098]],\n",
              "\n",
              "        [[3.25427  , 2.6941478, 3.0031807],\n",
              "         [3.2349555, 2.7327769, 3.0611243],\n",
              "         [3.2735846, 2.7134624, 3.1190681],\n",
              "         ...,\n",
              "         [3.0804389, 2.6168895, 3.0031807],\n",
              "         [3.0804389, 2.6168895, 3.0418098],\n",
              "         [3.0804389, 2.6168895, 3.0611243]],\n",
              "\n",
              "        [[3.3122137, 2.7520914, 3.0418098],\n",
              "         [3.2735846, 2.7327769, 3.0418098],\n",
              "         [3.2928991, 2.7520914, 3.1770117],\n",
              "         ...,\n",
              "         [3.0997536, 2.597575 , 3.0224953],\n",
              "         [3.0997536, 2.636204 , 3.0418098],\n",
              "         [3.0611243, 2.6168895, 3.1190681]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[3.3508427, 2.8293498, 3.1190681],\n",
              "         [3.3122137, 2.7520914, 3.0418098],\n",
              "         [3.3122137, 2.8679788, 3.0804389],\n",
              "         ...,\n",
              "         [3.1963263, 2.6941478, 3.0224953],\n",
              "         [3.25427  , 2.674833 , 2.9838662],\n",
              "         [3.1383827, 2.6941478, 2.9645517]],\n",
              "\n",
              "        [[3.3701575, 2.8293498, 3.0611243],\n",
              "         [3.2735846, 2.7907205, 3.0611243],\n",
              "         [3.3508427, 2.8486643, 3.1190681],\n",
              "         ...,\n",
              "         [3.2735846, 2.674833 , 3.0031807],\n",
              "         [3.2349555, 2.6941478, 2.9645517],\n",
              "         [3.1963263, 2.6555185, 3.0031807]],\n",
              "\n",
              "        [[3.2928991, 2.8293498, 3.0418098],\n",
              "         [3.25427  , 2.8293498, 3.0804389],\n",
              "         [3.3315282, 2.8486643, 3.1190681],\n",
              "         ...,\n",
              "         [3.2928991, 2.6941478, 3.0031807],\n",
              "         [3.25427  , 2.6555185, 2.9259224],\n",
              "         [3.1576972, 2.6168895, 2.8679788]]],\n",
              "\n",
              "\n",
              "       [[[4.2972565, 3.2156408, 3.1770117],\n",
              "         [4.3745146, 3.2735846, 3.2928991],\n",
              "         [4.3552   , 3.2928991, 3.3315282],\n",
              "         ...,\n",
              "         [4.4517727, 3.2349555, 2.9838662],\n",
              "         [4.4710875, 3.3122137, 3.0031807],\n",
              "         [4.4517727, 3.2735846, 3.0031807]],\n",
              "\n",
              "        [[4.219998 , 3.1383827, 3.0804389],\n",
              "         [4.2779417, 3.1963263, 3.2156408],\n",
              "         [4.3552   , 3.25427  , 3.2735846],\n",
              "         ...,\n",
              "         [4.4517727, 3.2349555, 2.9645517],\n",
              "         [4.5483456, 3.2735846, 3.0224953],\n",
              "         [4.4904017, 3.25427  , 3.0224953]],\n",
              "\n",
              "        [[4.181369 , 3.0804389, 3.0418098],\n",
              "         [4.219998 , 3.1383827, 3.1190681],\n",
              "         [4.3552   , 3.25427  , 3.3315282],\n",
              "         ...,\n",
              "         [4.5097165, 3.25427  , 2.9838662],\n",
              "         [4.529031 , 3.2928991, 3.0611243],\n",
              "         [4.5676603, 3.2928991, 3.0418098]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[4.6449184, 3.2349555, 2.9645517],\n",
              "         [4.6256037, 3.2156408, 2.9066079],\n",
              "         [4.5483456, 3.1383827, 2.7907205],\n",
              "         ...,\n",
              "         [4.2779417, 3.1383827, 3.0997536],\n",
              "         [4.219998 , 3.0997536, 3.0804389],\n",
              "         [4.219998 , 3.0611243, 3.0804389]],\n",
              "\n",
              "        [[4.5676603, 3.1963263, 2.9259224],\n",
              "         [4.6642327, 3.25427  , 3.0031807],\n",
              "         [4.7028623, 3.2735846, 3.0031807],\n",
              "         ...,\n",
              "         [4.219998 , 3.1383827, 3.1190681],\n",
              "         [4.2006836, 3.0997536, 3.0804389],\n",
              "         [4.2393126, 3.1190681, 3.0997536]],\n",
              "\n",
              "        [[4.6062894, 3.25427  , 2.9645517],\n",
              "         [4.6642327, 3.2735846, 3.0224953],\n",
              "         [4.7028623, 3.2928991, 3.0031807],\n",
              "         ...,\n",
              "         [4.2006836, 3.1383827, 3.0804389],\n",
              "         [4.2006836, 3.0804389, 3.0611243],\n",
              "         [4.219998 , 3.0997536, 3.0804389]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[3.2735846, 2.5203166, 2.5396311],\n",
              "         [3.2735846, 2.5203166, 2.5782604],\n",
              "         [3.3122137, 2.636204 , 2.6555185],\n",
              "         ...,\n",
              "         [2.9259224, 1.9988234, 1.9215652],\n",
              "         [2.8486643, 1.9408797, 1.7477341],\n",
              "         [2.771406 , 1.8249923, 1.5545884]],\n",
              "\n",
              "        [[3.25427  , 2.423744 , 2.4430585],\n",
              "         [3.2735846, 2.501002 , 2.5203166],\n",
              "         [3.3122137, 2.6168895, 2.6168895],\n",
              "         ...,\n",
              "         [2.8679788, 1.9795089, 1.8249923],\n",
              "         [2.7520914, 1.7670486, 1.5932176],\n",
              "         [2.7907205, 1.709105 , 1.4966449]],\n",
              "\n",
              "        [[3.2349555, 2.3851147, 2.3851147],\n",
              "         [3.2735846, 2.501002 , 2.501002 ],\n",
              "         [3.2928991, 2.5396311, 2.501002 ],\n",
              "         ...,\n",
              "         [2.7520914, 1.8249923, 1.6897904],\n",
              "         [2.7327769, 1.7477341, 1.5932176],\n",
              "         [2.8293498, 1.7670486, 1.5545884]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[3.4087865, 2.7327769, 2.8486643],\n",
              "         [3.3315282, 2.558946 , 2.7134624],\n",
              "         [3.3508427, 2.558946 , 2.7520914],\n",
              "         ...,\n",
              "         [2.7907205, 1.8056778, 1.7284195],\n",
              "         [2.771406 , 1.7670486, 1.7670486],\n",
              "         [2.7907205, 1.8056778, 1.7670486]],\n",
              "\n",
              "        [[3.3701575, 2.6555185, 2.8293498],\n",
              "         [3.4087865, 2.6941478, 2.8293498],\n",
              "         [3.389472 , 2.674833 , 2.810035 ],\n",
              "         ...,\n",
              "         [2.771406 , 1.7863632, 1.7284195],\n",
              "         [2.7134624, 1.6704758, 1.6511613],\n",
              "         [2.771406 , 1.7477341, 1.7284195]],\n",
              "\n",
              "        [[3.3508427, 2.636204 , 2.7907205],\n",
              "         [3.4087865, 2.7520914, 2.8872933],\n",
              "         [3.428101 , 2.771406 , 2.9066079],\n",
              "         ...,\n",
              "         [2.7520914, 1.8056778, 1.6704758],\n",
              "         [2.7327769, 1.709105 , 1.709105 ],\n",
              "         [2.7520914, 1.6897904, 1.6125321]]],\n",
              "\n",
              "\n",
              "       [[[2.9259224, 2.6168895, 2.4430585],\n",
              "         [2.9259224, 2.674833 , 2.4430585],\n",
              "         [3.0611243, 2.7907205, 2.636204 ],\n",
              "         ...,\n",
              "         [3.46673  , 3.2156408, 3.2928991],\n",
              "         [3.3508427, 3.1963263, 3.25427  ],\n",
              "         [3.3315282, 3.0997536, 3.1963263]],\n",
              "\n",
              "        [[2.8872933, 2.7134624, 2.462373 ],\n",
              "         [2.9838662, 2.7327769, 2.5203166],\n",
              "         [3.0804389, 2.7907205, 2.6941478],\n",
              "         ...,\n",
              "         [3.5826175, 3.2928991, 3.3315282],\n",
              "         [3.428101 , 3.1963263, 3.2928991],\n",
              "         [3.3315282, 3.1576972, 3.1963263]],\n",
              "\n",
              "        [[2.945237 , 2.7134624, 2.462373 ],\n",
              "         [3.0031807, 2.7520914, 2.5782604],\n",
              "         [3.1383827, 2.8486643, 2.6555185],\n",
              "         ...,\n",
              "         [3.5439885, 3.3508427, 3.428101 ],\n",
              "         [3.4860446, 3.2349555, 3.25427  ],\n",
              "         [3.3508427, 3.1963263, 3.2349555]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[3.2928991, 2.9645517, 2.810035 ],\n",
              "         [3.389472 , 3.0611243, 2.9259224],\n",
              "         [3.389472 , 3.0997536, 3.0031807],\n",
              "         ...,\n",
              "         [3.9302797, 3.524674 , 3.5053594],\n",
              "         [3.872336 , 3.5439885, 3.4474156],\n",
              "         [3.8143923, 3.5439885, 3.524674 ]],\n",
              "\n",
              "        [[3.25427  , 2.9066079, 2.7907205],\n",
              "         [3.389472 , 3.0031807, 2.9259224],\n",
              "         [3.3122137, 3.0611243, 2.9838662],\n",
              "         ...,\n",
              "         [3.910965 , 3.5439885, 3.4860446],\n",
              "         [3.8916504, 3.524674 , 3.5053594],\n",
              "         [3.8916504, 3.5439885, 3.5053594]],\n",
              "\n",
              "        [[3.2349555, 2.9259224, 2.8293498],\n",
              "         [3.3122137, 2.9838662, 2.8679788],\n",
              "         [3.3315282, 3.0611243, 2.8872933],\n",
              "         ...,\n",
              "         [3.872336 , 3.524674 , 3.46673  ],\n",
              "         [3.9882233, 3.5826175, 3.46673  ],\n",
              "         [3.8337069, 3.563303 , 3.4474156]]],\n",
              "\n",
              "\n",
              "       [[[4.3552   , 2.7134624, 2.6555185],\n",
              "         [4.393829 , 2.7134624, 2.7907205],\n",
              "         [4.3745146, 2.7134624, 2.7520914],\n",
              "         ...,\n",
              "         [4.3552   , 2.5396311, 2.771406 ],\n",
              "         [4.2779417, 2.4816875, 2.7327769],\n",
              "         [4.3745146, 2.5396311, 2.7520914]],\n",
              "\n",
              "        [[4.3745146, 2.6941478, 2.6941478],\n",
              "         [4.3745146, 2.674833 , 2.7327769],\n",
              "         [4.4131436, 2.7134624, 2.7907205],\n",
              "         ...,\n",
              "         [4.2972565, 2.5203166, 2.7134624],\n",
              "         [4.2972565, 2.5396311, 2.7134624],\n",
              "         [4.2779417, 2.5203166, 2.7134624]],\n",
              "\n",
              "        [[4.3745146, 2.674833 , 2.7134624],\n",
              "         [4.393829 , 2.674833 , 2.6941478],\n",
              "         [4.3745146, 2.6555185, 2.7520914],\n",
              "         ...,\n",
              "         [4.3745146, 2.5396311, 2.7520914],\n",
              "         [4.3165708, 2.5396311, 2.7134624],\n",
              "         [4.3745146, 2.6168895, 2.7327769]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[4.1041107, 2.462373 , 2.327171 ],\n",
              "         [4.181369 , 2.4816875, 2.4044294],\n",
              "         [4.2006836, 2.558946 , 2.4430585],\n",
              "         ...,\n",
              "         [3.9689088, 2.5203166, 2.3658001],\n",
              "         [3.9689088, 2.4430585, 2.3078566],\n",
              "         [4.0268526, 2.597575 , 2.4044294]],\n",
              "\n",
              "        [[4.14274  , 2.423744 , 2.3851147],\n",
              "         [4.1620545, 2.5203166, 2.4044294],\n",
              "         [4.084796 , 2.5203166, 2.3851147],\n",
              "         ...,\n",
              "         [3.9495943, 2.462373 , 2.3078566],\n",
              "         [3.9495943, 2.4430585, 2.327171 ],\n",
              "         [4.046167 , 2.558946 , 2.3851147]],\n",
              "\n",
              "        [[4.1041107, 2.4430585, 2.327171 ],\n",
              "         [4.1234255, 2.4816875, 2.3078566],\n",
              "         [4.14274  , 2.462373 , 2.327171 ],\n",
              "         ...,\n",
              "         [3.9302797, 2.462373 , 2.288542 ],\n",
              "         [3.9882233, 2.4816875, 2.3851147],\n",
              "         [4.046167 , 2.558946 , 2.3658001]]]],\n",
              "      shape=(8111, 224, 224, 3), dtype=float32)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "az43Zhha9oQj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, Input\n",
        "from sklearn.decomposition import PCA, FactorAnalysis\n",
        "\n",
        "# ---------------- Define First CNN ----------------\n",
        "def build_cnn1(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(32, (3,3), activation='relu')(inputs)\n",
        "    x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "    x = Conv2D(64, (3,3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "    x = Conv2D(128, (3,3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "    x = Conv2D(256, (3,3), activation='relu')(x)\n",
        "    x = MaxPooling2D((2,2))(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    return Model(inputs, x, name=\"CNN1\")\n",
        "\n",
        "# ---------------- Define Second CNN ----------------\n",
        "def build_cnn2(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(256, (7,7), activation='relu')(inputs)\n",
        "    x = AveragePooling2D((2,2))(x)\n",
        "\n",
        "    x = Conv2D(128, (5,5), activation='relu')(x)\n",
        "    x = AveragePooling2D((2,2))(x)\n",
        "\n",
        "    x = Conv2D(96, (3,3), activation='relu')(x)\n",
        "    x = AveragePooling2D((2,2))(x)\n",
        "\n",
        "    x = Conv2D(96, (3,3), activation='relu')(x)\n",
        "    x = AveragePooling2D((2,2))(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    return Model(inputs, x, name=\"CNN2\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "datagen.fit(X_train_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- CNN1 Summary ----\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"CNN1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">388,416</span> (1.48 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m388,416\u001b[0m (1.48 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">388,416</span> (1.48 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m388,416\u001b[0m (1.48 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---- CNN2 Summary ----\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"CNN2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">218</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">218</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,888</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">105</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">819,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">110,688</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">83,040</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11616</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m218\u001b[0m, \u001b[38;5;34m218\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │        \u001b[38;5;34m37,888\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m105\u001b[0m, \u001b[38;5;34m105\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m819,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │       \u001b[38;5;34m110,688\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │        \u001b[38;5;34m83,040\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m96\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11616\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,944</span> (4.01 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,050,944\u001b[0m (4.01 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,944</span> (4.01 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,050,944\u001b[0m (4.01 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input_shape = (224, 224, 3)\n",
        "CNN1 = build_cnn1(input_shape)\n",
        "CNN2 = build_cnn2(input_shape)\n",
        "print(\"---- CNN1 Summary ----\")\n",
        "CNN1.summary()\n",
        "\n",
        "print(\"\\n---- CNN2 Summary ----\")\n",
        "CNN2.summary()\n",
        "# Use augmented data for feature extraction\n",
        "train_generator = datagen.flow(X_train_images, y_train, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.legacy.preprocessing.image.NumpyArrayIterator at 0x10ed6409590>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 267ms/step\n",
            "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1212s\u001b[0m 5s/step\n"
          ]
        }
      ],
      "source": [
        "features_cnn1 = CNN1.predict(train_generator, verbose=1)\n",
        "features_cnn2 = CNN2.predict(train_generator, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ompat\\OneDrive\\Desktop\\Skin-Cancer-Classification\\venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 148ms/step\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step\n"
          ]
        }
      ],
      "source": [
        "# Validation generator (no augmentation)\n",
        "val_datagen = ImageDataGenerator()\n",
        "\n",
        "val_generator = val_datagen.flow(\n",
        "    X_val_images, y_val,\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Now extract features\n",
        "features_cnn1_val = CNN1.predict(val_generator, verbose=1)\n",
        "features_cnn2_val = CNN2.predict(val_generator, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------------- Dimensionality Reduction ----------------\n",
        "pca = PCA(n_components=50)\n",
        "features_pca = pca.fit_transform(features_cnn1)\n",
        "features_pca_val = pca.transform(features_cnn1_val)\n",
        "\n",
        "fa = FactorAnalysis(n_components=50)\n",
        "features_fa = fa.fit_transform(features_cnn2)\n",
        "features_fa_val = fa.transform(features_cnn2_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge\n",
        "merged_features = np.concatenate([features_pca, features_fa], axis=1)\n",
        "merged_features_val = np.concatenate([features_pca_val, features_fa_val], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---- Classifier Summary ----\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">455</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m12,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m455\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,639</span> (84.53 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,639\u001b[0m (84.53 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,639</span> (84.53 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,639\u001b[0m (84.53 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# ---------------- Classifier ----------------\n",
        "classifier = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(merged_features.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(7, activation='softmax')  # 7 classes\n",
        "])\n",
        "print(\"\\n---- Classifier Summary ----\")\n",
        "classifier.summary()\n",
        "\n",
        "classifier.compile(optimizer='adam',\n",
        "                   loss='sparse_categorical_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "# Early stopping callback\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.3172 - val_accuracy: 0.7062 - val_loss: 1.3521\n",
            "Epoch 2/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8809 - loss: 0.3162 - val_accuracy: 0.7062 - val_loss: 1.3737\n",
            "Epoch 3/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8777 - loss: 0.3211 - val_accuracy: 0.7073 - val_loss: 1.3254\n",
            "Epoch 4/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8805 - loss: 0.3191 - val_accuracy: 0.7095 - val_loss: 1.3097\n",
            "Epoch 5/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.3162 - val_accuracy: 0.7151 - val_loss: 1.3565\n",
            "Epoch 6/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.3008 - val_accuracy: 0.7084 - val_loss: 1.3436\n",
            "Epoch 7/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8883 - loss: 0.2975 - val_accuracy: 0.7095 - val_loss: 1.3675\n",
            "Epoch 8/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8804 - loss: 0.3112 - val_accuracy: 0.7051 - val_loss: 1.3274\n",
            "Epoch 9/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.3028 - val_accuracy: 0.6973 - val_loss: 1.3387\n",
            "Epoch 10/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 0.3113 - val_accuracy: 0.7051 - val_loss: 1.3381\n",
            "Epoch 11/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.3137 - val_accuracy: 0.7084 - val_loss: 1.3334\n",
            "Epoch 12/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8876 - loss: 0.2980 - val_accuracy: 0.7007 - val_loss: 1.3687\n",
            "Epoch 13/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.3008 - val_accuracy: 0.7029 - val_loss: 1.3495\n",
            "Epoch 14/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8847 - loss: 0.3041 - val_accuracy: 0.7029 - val_loss: 1.4001\n",
            "Epoch 15/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8890 - loss: 0.2889 - val_accuracy: 0.6951 - val_loss: 1.4093\n",
            "Epoch 16/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8867 - loss: 0.2911 - val_accuracy: 0.7084 - val_loss: 1.4196\n",
            "Epoch 17/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8930 - loss: 0.2846 - val_accuracy: 0.7051 - val_loss: 1.3918\n",
            "Epoch 18/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8932 - loss: 0.2901 - val_accuracy: 0.7040 - val_loss: 1.4049\n",
            "Epoch 19/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.2925 - val_accuracy: 0.6984 - val_loss: 1.3992\n",
            "Epoch 20/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.2969 - val_accuracy: 0.7084 - val_loss: 1.3986\n",
            "Epoch 21/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.2869 - val_accuracy: 0.7018 - val_loss: 1.4032\n",
            "Epoch 22/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.2859 - val_accuracy: 0.7040 - val_loss: 1.4341\n",
            "Epoch 23/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.2896 - val_accuracy: 0.7051 - val_loss: 1.4224\n",
            "Epoch 24/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.2774 - val_accuracy: 0.6940 - val_loss: 1.4456\n",
            "Epoch 25/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.3112 - val_accuracy: 0.7118 - val_loss: 1.3822\n",
            "Epoch 26/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8881 - loss: 0.2976 - val_accuracy: 0.7062 - val_loss: 1.3897\n",
            "Epoch 27/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2759 - val_accuracy: 0.7073 - val_loss: 1.4043\n",
            "Epoch 28/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.2794 - val_accuracy: 0.7118 - val_loss: 1.3966\n",
            "Epoch 29/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8973 - loss: 0.2729 - val_accuracy: 0.7129 - val_loss: 1.4745\n",
            "Epoch 30/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.2892 - val_accuracy: 0.6973 - val_loss: 1.4289\n",
            "Epoch 31/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8972 - loss: 0.2792 - val_accuracy: 0.7106 - val_loss: 1.4486\n",
            "Epoch 32/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.2814 - val_accuracy: 0.7007 - val_loss: 1.4556\n",
            "Epoch 33/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.2684 - val_accuracy: 0.7118 - val_loss: 1.4383\n",
            "Epoch 34/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.2657 - val_accuracy: 0.7084 - val_loss: 1.4952\n",
            "Epoch 35/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8936 - loss: 0.2822 - val_accuracy: 0.7029 - val_loss: 1.4863\n",
            "Epoch 36/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.2804 - val_accuracy: 0.7151 - val_loss: 1.4727\n",
            "Epoch 37/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8952 - loss: 0.2826 - val_accuracy: 0.7151 - val_loss: 1.4476\n",
            "Epoch 38/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.2656 - val_accuracy: 0.7239 - val_loss: 1.4615\n",
            "Epoch 39/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.2801 - val_accuracy: 0.7140 - val_loss: 1.4184\n",
            "Epoch 40/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8942 - loss: 0.2780 - val_accuracy: 0.7029 - val_loss: 1.4760\n",
            "Epoch 41/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.2811 - val_accuracy: 0.6996 - val_loss: 1.4838\n",
            "Epoch 42/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.2767 - val_accuracy: 0.7007 - val_loss: 1.4722\n",
            "Epoch 43/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.2743 - val_accuracy: 0.7018 - val_loss: 1.5046\n",
            "Epoch 44/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9033 - loss: 0.2682 - val_accuracy: 0.7007 - val_loss: 1.4937\n",
            "Epoch 45/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.2862 - val_accuracy: 0.6973 - val_loss: 1.4629\n",
            "Epoch 46/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.2761 - val_accuracy: 0.6885 - val_loss: 1.5033\n",
            "Epoch 47/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8998 - loss: 0.2735 - val_accuracy: 0.7040 - val_loss: 1.5383\n",
            "Epoch 48/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8953 - loss: 0.2820 - val_accuracy: 0.7018 - val_loss: 1.5523\n",
            "Epoch 49/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.2791 - val_accuracy: 0.6984 - val_loss: 1.5378\n",
            "Epoch 50/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8984 - loss: 0.2696 - val_accuracy: 0.7040 - val_loss: 1.5634\n",
            "Epoch 51/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.2680 - val_accuracy: 0.7040 - val_loss: 1.5091\n",
            "Epoch 52/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 0.2676 - val_accuracy: 0.7073 - val_loss: 1.5496\n",
            "Epoch 53/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.2680 - val_accuracy: 0.6885 - val_loss: 1.5754\n",
            "Epoch 54/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9054 - loss: 0.2574 - val_accuracy: 0.6984 - val_loss: 1.5972\n",
            "Epoch 55/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.2507 - val_accuracy: 0.7051 - val_loss: 1.6137\n",
            "Epoch 56/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.2595 - val_accuracy: 0.7073 - val_loss: 1.6213\n",
            "Epoch 57/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2557 - val_accuracy: 0.7073 - val_loss: 1.6287\n",
            "Epoch 58/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.2649 - val_accuracy: 0.7106 - val_loss: 1.6457\n",
            "Epoch 59/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8971 - loss: 0.2696 - val_accuracy: 0.7062 - val_loss: 1.6206\n",
            "Epoch 60/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9030 - loss: 0.2684 - val_accuracy: 0.7040 - val_loss: 1.6560\n",
            "Epoch 61/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.2535 - val_accuracy: 0.6973 - val_loss: 1.6484\n",
            "Epoch 62/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.2633 - val_accuracy: 0.7029 - val_loss: 1.6289\n",
            "Epoch 63/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.2523 - val_accuracy: 0.7129 - val_loss: 1.6480\n",
            "Epoch 64/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.2511 - val_accuracy: 0.7084 - val_loss: 1.6159\n",
            "Epoch 65/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.2494 - val_accuracy: 0.6984 - val_loss: 1.7014\n",
            "Epoch 66/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9056 - loss: 0.2568 - val_accuracy: 0.6962 - val_loss: 1.6862\n",
            "Epoch 67/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8993 - loss: 0.2680 - val_accuracy: 0.7018 - val_loss: 1.6702\n",
            "Epoch 68/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9012 - loss: 0.2611 - val_accuracy: 0.7062 - val_loss: 1.6905\n",
            "Epoch 69/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.2494 - val_accuracy: 0.6996 - val_loss: 1.7083\n",
            "Epoch 70/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2446 - val_accuracy: 0.7051 - val_loss: 1.7404\n",
            "Epoch 71/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9079 - loss: 0.2456 - val_accuracy: 0.7029 - val_loss: 1.7171\n",
            "Epoch 72/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9052 - loss: 0.2547 - val_accuracy: 0.6940 - val_loss: 1.6817\n",
            "Epoch 73/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2579 - val_accuracy: 0.7018 - val_loss: 1.7289\n",
            "Epoch 74/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9033 - loss: 0.2548 - val_accuracy: 0.6929 - val_loss: 1.7268\n",
            "Epoch 75/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9068 - loss: 0.2559 - val_accuracy: 0.6984 - val_loss: 1.7550\n",
            "Epoch 76/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2511 - val_accuracy: 0.6840 - val_loss: 1.7713\n",
            "Epoch 77/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.2509 - val_accuracy: 0.6929 - val_loss: 1.7671\n",
            "Epoch 78/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2523 - val_accuracy: 0.6962 - val_loss: 1.7729\n",
            "Epoch 79/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9033 - loss: 0.2542 - val_accuracy: 0.6907 - val_loss: 1.7306\n",
            "Epoch 80/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2249 - val_accuracy: 0.7040 - val_loss: 1.7483\n",
            "Epoch 81/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.2797 - val_accuracy: 0.7007 - val_loss: 1.7909\n",
            "Epoch 82/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9022 - loss: 0.2524 - val_accuracy: 0.7073 - val_loss: 1.7792\n",
            "Epoch 83/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2486 - val_accuracy: 0.7173 - val_loss: 1.7830\n",
            "Epoch 84/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.2430 - val_accuracy: 0.7118 - val_loss: 1.7412\n",
            "Epoch 85/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2447 - val_accuracy: 0.7129 - val_loss: 1.8220\n",
            "Epoch 86/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9079 - loss: 0.2537 - val_accuracy: 0.7073 - val_loss: 1.7670\n",
            "Epoch 87/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2500 - val_accuracy: 0.7106 - val_loss: 1.7623\n",
            "Epoch 88/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.2400 - val_accuracy: 0.7073 - val_loss: 1.8051\n",
            "Epoch 89/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9074 - loss: 0.2503 - val_accuracy: 0.7129 - val_loss: 1.8149\n",
            "Epoch 90/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2383 - val_accuracy: 0.7040 - val_loss: 1.8344\n",
            "Epoch 91/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9067 - loss: 0.2433 - val_accuracy: 0.7106 - val_loss: 1.8448\n",
            "Epoch 92/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2463 - val_accuracy: 0.7106 - val_loss: 1.8640\n",
            "Epoch 93/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2341 - val_accuracy: 0.7062 - val_loss: 1.8907\n",
            "Epoch 94/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.2539 - val_accuracy: 0.7007 - val_loss: 1.8796\n",
            "Epoch 95/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9094 - loss: 0.2470 - val_accuracy: 0.6996 - val_loss: 1.8828\n",
            "Epoch 96/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2352 - val_accuracy: 0.7018 - val_loss: 1.8897\n",
            "Epoch 97/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2370 - val_accuracy: 0.7007 - val_loss: 1.8712\n",
            "Epoch 98/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2407 - val_accuracy: 0.6962 - val_loss: 1.8695\n",
            "Epoch 99/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.2375 - val_accuracy: 0.6962 - val_loss: 1.9187\n",
            "Epoch 100/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2373 - val_accuracy: 0.6984 - val_loss: 1.9277\n",
            "Epoch 101/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9067 - loss: 0.2409 - val_accuracy: 0.7073 - val_loss: 1.9303\n",
            "Epoch 102/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2423 - val_accuracy: 0.7007 - val_loss: 1.9056\n",
            "Epoch 103/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2320 - val_accuracy: 0.6973 - val_loss: 1.9229\n",
            "Epoch 104/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2341 - val_accuracy: 0.7007 - val_loss: 1.9328\n",
            "Epoch 105/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2429 - val_accuracy: 0.6951 - val_loss: 1.9245\n",
            "Epoch 106/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9085 - loss: 0.2434 - val_accuracy: 0.6973 - val_loss: 1.9525\n",
            "Epoch 107/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2407 - val_accuracy: 0.7029 - val_loss: 1.9129\n",
            "Epoch 108/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2325 - val_accuracy: 0.7040 - val_loss: 2.0125\n",
            "Epoch 109/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2492 - val_accuracy: 0.7095 - val_loss: 1.9751\n",
            "Epoch 110/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2391 - val_accuracy: 0.7118 - val_loss: 1.9642\n",
            "Epoch 111/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9093 - loss: 0.2411 - val_accuracy: 0.7062 - val_loss: 1.9429\n",
            "Epoch 112/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2251 - val_accuracy: 0.6973 - val_loss: 1.9861\n",
            "Epoch 113/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2224 - val_accuracy: 0.7051 - val_loss: 2.0455\n",
            "Epoch 114/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.2459 - val_accuracy: 0.7051 - val_loss: 1.9951\n",
            "Epoch 115/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2302 - val_accuracy: 0.7073 - val_loss: 1.9855\n",
            "Epoch 116/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2423 - val_accuracy: 0.6940 - val_loss: 1.9754\n",
            "Epoch 117/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2296 - val_accuracy: 0.7106 - val_loss: 1.9471\n",
            "Epoch 118/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2293 - val_accuracy: 0.6973 - val_loss: 2.0083\n",
            "Epoch 119/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2265 - val_accuracy: 0.6984 - val_loss: 2.0093\n",
            "Epoch 120/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2371 - val_accuracy: 0.6896 - val_loss: 1.9905\n",
            "Epoch 121/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2195 - val_accuracy: 0.7040 - val_loss: 1.9968\n",
            "Epoch 122/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2342 - val_accuracy: 0.6940 - val_loss: 1.9713\n",
            "Epoch 123/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2340 - val_accuracy: 0.6940 - val_loss: 2.0064\n",
            "Epoch 124/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2293 - val_accuracy: 0.6996 - val_loss: 1.9865\n",
            "Epoch 125/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2263 - val_accuracy: 0.6929 - val_loss: 1.9809\n",
            "Epoch 126/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2361 - val_accuracy: 0.6996 - val_loss: 1.9925\n",
            "Epoch 127/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2311 - val_accuracy: 0.6951 - val_loss: 1.9981\n",
            "Epoch 128/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2264 - val_accuracy: 0.7007 - val_loss: 2.0357\n",
            "Epoch 129/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2248 - val_accuracy: 0.7029 - val_loss: 2.0132\n",
            "Epoch 130/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2213 - val_accuracy: 0.7018 - val_loss: 2.0649\n",
            "Epoch 131/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9085 - loss: 0.2275 - val_accuracy: 0.7040 - val_loss: 2.1037\n",
            "Epoch 132/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2292 - val_accuracy: 0.6962 - val_loss: 2.0925\n",
            "Epoch 133/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2210 - val_accuracy: 0.7007 - val_loss: 2.1071\n",
            "Epoch 134/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2268 - val_accuracy: 0.7040 - val_loss: 2.0893\n",
            "Epoch 135/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2257 - val_accuracy: 0.6962 - val_loss: 2.0761\n",
            "Epoch 136/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2274 - val_accuracy: 0.6996 - val_loss: 2.0786\n",
            "Epoch 137/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2229 - val_accuracy: 0.7029 - val_loss: 2.1487\n",
            "Epoch 138/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9173 - loss: 0.2126 - val_accuracy: 0.7106 - val_loss: 2.1164\n",
            "Epoch 139/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2197 - val_accuracy: 0.7007 - val_loss: 2.1232\n",
            "Epoch 140/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2226 - val_accuracy: 0.7007 - val_loss: 2.1806\n",
            "Epoch 141/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.2365 - val_accuracy: 0.6996 - val_loss: 2.1554\n",
            "Epoch 142/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9228 - loss: 0.2112 - val_accuracy: 0.7073 - val_loss: 2.2146\n",
            "Epoch 143/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.2218 - val_accuracy: 0.6973 - val_loss: 2.1980\n",
            "Epoch 144/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.2171 - val_accuracy: 0.7007 - val_loss: 2.1937\n",
            "Epoch 145/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2264 - val_accuracy: 0.6940 - val_loss: 2.1761\n",
            "Epoch 146/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.2180 - val_accuracy: 0.6929 - val_loss: 2.1519\n",
            "Epoch 147/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2264 - val_accuracy: 0.6929 - val_loss: 2.1724\n",
            "Epoch 148/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2264 - val_accuracy: 0.6962 - val_loss: 2.1719\n",
            "Epoch 149/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.2159 - val_accuracy: 0.6940 - val_loss: 2.1300\n",
            "Epoch 150/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2263 - val_accuracy: 0.6874 - val_loss: 2.1691\n",
            "Epoch 151/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2143 - val_accuracy: 0.6918 - val_loss: 2.2301\n",
            "Epoch 152/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2307 - val_accuracy: 0.6951 - val_loss: 2.1448\n",
            "Epoch 153/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2206 - val_accuracy: 0.7040 - val_loss: 2.1252\n",
            "Epoch 154/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2210 - val_accuracy: 0.7007 - val_loss: 2.1278\n",
            "Epoch 155/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.2165 - val_accuracy: 0.7007 - val_loss: 2.1336\n",
            "Epoch 156/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.2104 - val_accuracy: 0.6984 - val_loss: 2.1726\n",
            "Epoch 157/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.2110 - val_accuracy: 0.6996 - val_loss: 2.2489\n",
            "Epoch 158/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2221 - val_accuracy: 0.6973 - val_loss: 2.2028\n",
            "Epoch 159/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2184 - val_accuracy: 0.6940 - val_loss: 2.1704\n",
            "Epoch 160/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2347 - val_accuracy: 0.7007 - val_loss: 2.1620\n",
            "Epoch 161/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2357 - val_accuracy: 0.6973 - val_loss: 2.2402\n",
            "Epoch 162/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.2210 - val_accuracy: 0.6996 - val_loss: 2.2741\n",
            "Epoch 163/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9216 - loss: 0.2144 - val_accuracy: 0.7151 - val_loss: 2.2546\n",
            "Epoch 164/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9220 - loss: 0.2070 - val_accuracy: 0.7007 - val_loss: 2.2591\n",
            "Epoch 165/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2243 - val_accuracy: 0.6973 - val_loss: 2.2855\n",
            "Epoch 166/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2224 - val_accuracy: 0.7029 - val_loss: 2.2862\n",
            "Epoch 167/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2143 - val_accuracy: 0.6973 - val_loss: 2.2835\n",
            "Epoch 168/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9217 - loss: 0.2071 - val_accuracy: 0.7018 - val_loss: 2.3175\n",
            "Epoch 169/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9216 - loss: 0.2048 - val_accuracy: 0.7040 - val_loss: 2.3636\n",
            "Epoch 170/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2059 - val_accuracy: 0.6962 - val_loss: 2.3110\n",
            "Epoch 171/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9225 - loss: 0.2066 - val_accuracy: 0.6907 - val_loss: 2.2888\n",
            "Epoch 172/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.2089 - val_accuracy: 0.6918 - val_loss: 2.3221\n",
            "Epoch 173/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.2173 - val_accuracy: 0.7018 - val_loss: 2.3160\n",
            "Epoch 174/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2233 - val_accuracy: 0.7073 - val_loss: 2.2922\n",
            "Epoch 175/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.2150 - val_accuracy: 0.7073 - val_loss: 2.2986\n",
            "Epoch 176/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2049 - val_accuracy: 0.6984 - val_loss: 2.3434\n",
            "Epoch 177/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.2254 - val_accuracy: 0.7029 - val_loss: 2.4810\n",
            "Epoch 178/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.2101 - val_accuracy: 0.7040 - val_loss: 2.5153\n",
            "Epoch 179/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2204 - val_accuracy: 0.6996 - val_loss: 2.5422\n",
            "Epoch 180/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2098 - val_accuracy: 0.6929 - val_loss: 2.5292\n",
            "Epoch 181/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9236 - loss: 0.2010 - val_accuracy: 0.6940 - val_loss: 2.5392\n",
            "Epoch 182/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9244 - loss: 0.1989 - val_accuracy: 0.6907 - val_loss: 2.5448\n",
            "Epoch 183/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9195 - loss: 0.2178 - val_accuracy: 0.6951 - val_loss: 2.5443\n",
            "Epoch 184/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.2227 - val_accuracy: 0.6962 - val_loss: 2.5222\n",
            "Epoch 185/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2133 - val_accuracy: 0.6918 - val_loss: 2.4960\n",
            "Epoch 186/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.2027 - val_accuracy: 0.6973 - val_loss: 2.5338\n",
            "Epoch 187/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2015 - val_accuracy: 0.6962 - val_loss: 2.6621\n",
            "Epoch 188/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9212 - loss: 0.2225 - val_accuracy: 0.6940 - val_loss: 2.6398\n",
            "Epoch 189/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9270 - loss: 0.1973 - val_accuracy: 0.6962 - val_loss: 2.6575\n",
            "Epoch 190/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9243 - loss: 0.2047 - val_accuracy: 0.7018 - val_loss: 2.6109\n",
            "Epoch 191/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.2176 - val_accuracy: 0.7018 - val_loss: 2.5324\n",
            "Epoch 192/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9248 - loss: 0.2105 - val_accuracy: 0.6918 - val_loss: 2.6064\n",
            "Epoch 193/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.2131 - val_accuracy: 0.6984 - val_loss: 2.5620\n",
            "Epoch 194/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9228 - loss: 0.2039 - val_accuracy: 0.6951 - val_loss: 2.6659\n",
            "Epoch 195/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9229 - loss: 0.2032 - val_accuracy: 0.6929 - val_loss: 2.7094\n",
            "Epoch 196/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2030 - val_accuracy: 0.7018 - val_loss: 2.6345\n",
            "Epoch 197/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9248 - loss: 0.1950 - val_accuracy: 0.6984 - val_loss: 2.6414\n",
            "Epoch 198/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9242 - loss: 0.2123 - val_accuracy: 0.6951 - val_loss: 2.6404\n",
            "Epoch 199/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9236 - loss: 0.2132 - val_accuracy: 0.6918 - val_loss: 2.7119\n",
            "Epoch 200/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2069 - val_accuracy: 0.6951 - val_loss: 2.6594\n",
            "Epoch 201/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.2144 - val_accuracy: 0.6984 - val_loss: 2.7026\n",
            "Epoch 202/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2084 - val_accuracy: 0.6984 - val_loss: 2.6692\n",
            "Epoch 203/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.2093 - val_accuracy: 0.6973 - val_loss: 2.6498\n",
            "Epoch 204/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9248 - loss: 0.1974 - val_accuracy: 0.7018 - val_loss: 2.6807\n",
            "Epoch 205/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.1981 - val_accuracy: 0.6951 - val_loss: 2.6876\n",
            "Epoch 206/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.1934 - val_accuracy: 0.6984 - val_loss: 2.7182\n",
            "Epoch 207/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2038 - val_accuracy: 0.6896 - val_loss: 2.6836\n",
            "Epoch 208/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.2109 - val_accuracy: 0.6996 - val_loss: 2.7088\n",
            "Epoch 209/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2074 - val_accuracy: 0.7018 - val_loss: 2.7138\n",
            "Epoch 210/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.1926 - val_accuracy: 0.6907 - val_loss: 2.7541\n",
            "Epoch 211/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.1924 - val_accuracy: 0.6984 - val_loss: 2.8595\n",
            "Epoch 212/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.2092 - val_accuracy: 0.6996 - val_loss: 2.7326\n",
            "Epoch 213/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9245 - loss: 0.2092 - val_accuracy: 0.6929 - val_loss: 2.7005\n",
            "Epoch 214/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9216 - loss: 0.2052 - val_accuracy: 0.6929 - val_loss: 2.6689\n",
            "Epoch 215/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2089 - val_accuracy: 0.6918 - val_loss: 2.7266\n",
            "Epoch 216/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2006 - val_accuracy: 0.6940 - val_loss: 2.6967\n",
            "Epoch 217/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.1937 - val_accuracy: 0.6907 - val_loss: 2.7431\n",
            "Epoch 218/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.2031 - val_accuracy: 0.6940 - val_loss: 2.8315\n",
            "Epoch 219/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9289 - loss: 0.2008 - val_accuracy: 0.6940 - val_loss: 2.7765\n",
            "Epoch 220/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9287 - loss: 0.1931 - val_accuracy: 0.6940 - val_loss: 2.7882\n",
            "Epoch 221/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.1904 - val_accuracy: 0.7029 - val_loss: 2.7845\n",
            "Epoch 222/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.1972 - val_accuracy: 0.6940 - val_loss: 2.8550\n",
            "Epoch 223/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.1900 - val_accuracy: 0.6918 - val_loss: 2.9052\n",
            "Epoch 224/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.1952 - val_accuracy: 0.6851 - val_loss: 2.8549\n",
            "Epoch 225/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.1857 - val_accuracy: 0.6796 - val_loss: 2.9108\n",
            "Epoch 226/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.1951 - val_accuracy: 0.6863 - val_loss: 2.9174\n",
            "Epoch 227/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.2069 - val_accuracy: 0.6818 - val_loss: 2.8415\n",
            "Epoch 228/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.2018 - val_accuracy: 0.6807 - val_loss: 2.8227\n",
            "Epoch 229/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2006 - val_accuracy: 0.6940 - val_loss: 2.8684\n",
            "Epoch 230/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9249 - loss: 0.2042 - val_accuracy: 0.6907 - val_loss: 2.8874\n",
            "Epoch 231/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.1999 - val_accuracy: 0.6929 - val_loss: 2.8732\n",
            "Epoch 232/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.1977 - val_accuracy: 0.6973 - val_loss: 2.8525\n",
            "Epoch 233/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9211 - loss: 0.2120 - val_accuracy: 0.6929 - val_loss: 2.8655\n",
            "Epoch 234/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.2051 - val_accuracy: 0.6874 - val_loss: 2.9289\n",
            "Epoch 235/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.2018 - val_accuracy: 0.6962 - val_loss: 2.9011\n",
            "Epoch 236/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2007 - val_accuracy: 0.7029 - val_loss: 2.8378\n",
            "Epoch 237/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9324 - loss: 0.1871 - val_accuracy: 0.7018 - val_loss: 2.8374\n",
            "Epoch 238/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9287 - loss: 0.2027 - val_accuracy: 0.6918 - val_loss: 2.8434\n",
            "Epoch 239/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9300 - loss: 0.1909 - val_accuracy: 0.6951 - val_loss: 2.8347\n",
            "Epoch 240/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9294 - loss: 0.1868 - val_accuracy: 0.6951 - val_loss: 2.9030\n",
            "Epoch 241/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.1940 - val_accuracy: 0.7051 - val_loss: 2.9578\n",
            "Epoch 242/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.1937 - val_accuracy: 0.6984 - val_loss: 2.8269\n",
            "Epoch 243/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9300 - loss: 0.1893 - val_accuracy: 0.7029 - val_loss: 2.8642\n",
            "Epoch 244/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9233 - loss: 0.2105 - val_accuracy: 0.7051 - val_loss: 2.8399\n",
            "Epoch 245/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.1937 - val_accuracy: 0.7062 - val_loss: 2.8611\n",
            "Epoch 246/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.2030 - val_accuracy: 0.6973 - val_loss: 2.8232\n",
            "Epoch 247/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9328 - loss: 0.1822 - val_accuracy: 0.7029 - val_loss: 2.8647\n",
            "Epoch 248/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9280 - loss: 0.2012 - val_accuracy: 0.7062 - val_loss: 2.8576\n",
            "Epoch 249/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9294 - loss: 0.1850 - val_accuracy: 0.6896 - val_loss: 2.8916\n",
            "Epoch 250/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9321 - loss: 0.1885 - val_accuracy: 0.6962 - val_loss: 2.9359\n",
            "Epoch 251/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.1946 - val_accuracy: 0.6973 - val_loss: 2.8866\n",
            "Epoch 252/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9329 - loss: 0.1836 - val_accuracy: 0.6951 - val_loss: 2.9627\n",
            "Epoch 253/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9335 - loss: 0.1833 - val_accuracy: 0.6874 - val_loss: 2.9591\n",
            "Epoch 254/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9339 - loss: 0.1885 - val_accuracy: 0.6918 - val_loss: 2.9349\n",
            "Epoch 255/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.2016 - val_accuracy: 0.6940 - val_loss: 2.9448\n",
            "Epoch 256/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.1953 - val_accuracy: 0.7007 - val_loss: 2.9302\n",
            "Epoch 257/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9315 - loss: 0.1866 - val_accuracy: 0.6874 - val_loss: 2.9254\n",
            "Epoch 258/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.1974 - val_accuracy: 0.6851 - val_loss: 2.8881\n",
            "Epoch 259/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.1950 - val_accuracy: 0.6973 - val_loss: 2.8982\n",
            "Epoch 260/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.1996 - val_accuracy: 0.6885 - val_loss: 2.8505\n",
            "Epoch 261/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.1936 - val_accuracy: 0.6874 - val_loss: 2.9372\n",
            "Epoch 262/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9303 - loss: 0.1934 - val_accuracy: 0.6962 - val_loss: 2.9229\n",
            "Epoch 263/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9286 - loss: 0.1934 - val_accuracy: 0.6885 - val_loss: 2.9660\n",
            "Epoch 264/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9306 - loss: 0.1859 - val_accuracy: 0.6840 - val_loss: 2.9699\n",
            "Epoch 265/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9296 - loss: 0.1853 - val_accuracy: 0.6907 - val_loss: 3.0200\n",
            "Epoch 266/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9358 - loss: 0.1772 - val_accuracy: 0.6885 - val_loss: 3.0918\n",
            "Epoch 267/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9343 - loss: 0.1805 - val_accuracy: 0.6918 - val_loss: 3.1203\n",
            "Epoch 268/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9313 - loss: 0.1864 - val_accuracy: 0.6896 - val_loss: 3.0746\n",
            "Epoch 269/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9305 - loss: 0.1939 - val_accuracy: 0.6918 - val_loss: 3.0341\n",
            "Epoch 270/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9355 - loss: 0.1781 - val_accuracy: 0.6885 - val_loss: 3.0939\n",
            "Epoch 271/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9337 - loss: 0.1796 - val_accuracy: 0.6907 - val_loss: 3.1237\n",
            "Epoch 272/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9337 - loss: 0.1777 - val_accuracy: 0.6896 - val_loss: 3.1390\n",
            "Epoch 273/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.2079 - val_accuracy: 0.6984 - val_loss: 3.0138\n",
            "Epoch 274/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9313 - loss: 0.1851 - val_accuracy: 0.6951 - val_loss: 3.0758\n",
            "Epoch 275/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.1945 - val_accuracy: 0.6851 - val_loss: 3.0532\n",
            "Epoch 276/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.1974 - val_accuracy: 0.6874 - val_loss: 3.0662\n",
            "Epoch 277/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.1921 - val_accuracy: 0.6940 - val_loss: 3.0544\n",
            "Epoch 278/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.1884 - val_accuracy: 0.6840 - val_loss: 3.0897\n",
            "Epoch 279/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9282 - loss: 0.1912 - val_accuracy: 0.6984 - val_loss: 3.1063\n",
            "Epoch 280/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9292 - loss: 0.1871 - val_accuracy: 0.6996 - val_loss: 3.1090\n",
            "Epoch 281/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9307 - loss: 0.1828 - val_accuracy: 0.6929 - val_loss: 3.0513\n",
            "Epoch 282/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9342 - loss: 0.1766 - val_accuracy: 0.6951 - val_loss: 3.1273\n",
            "Epoch 283/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9322 - loss: 0.1863 - val_accuracy: 0.6874 - val_loss: 3.0679\n",
            "Epoch 284/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.1881 - val_accuracy: 0.6940 - val_loss: 3.0929\n",
            "Epoch 285/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9308 - loss: 0.1885 - val_accuracy: 0.6741 - val_loss: 3.0388\n",
            "Epoch 286/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.1904 - val_accuracy: 0.6885 - val_loss: 3.0735\n",
            "Epoch 287/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9324 - loss: 0.2069 - val_accuracy: 0.6840 - val_loss: 3.1767\n",
            "Epoch 288/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.1876 - val_accuracy: 0.6896 - val_loss: 3.2007\n",
            "Epoch 289/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.1726 - val_accuracy: 0.6885 - val_loss: 3.1704\n",
            "Epoch 290/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9297 - loss: 0.1927 - val_accuracy: 0.6863 - val_loss: 3.1122\n",
            "Epoch 291/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9292 - loss: 0.1920 - val_accuracy: 0.6874 - val_loss: 3.1282\n",
            "Epoch 292/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9292 - loss: 0.1915 - val_accuracy: 0.6885 - val_loss: 3.0964\n",
            "Epoch 293/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9313 - loss: 0.1929 - val_accuracy: 0.6796 - val_loss: 3.1002\n",
            "Epoch 294/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.1752 - val_accuracy: 0.6807 - val_loss: 3.1805\n",
            "Epoch 295/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9348 - loss: 0.1731 - val_accuracy: 0.6874 - val_loss: 3.2038\n",
            "Epoch 296/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9342 - loss: 0.1767 - val_accuracy: 0.6752 - val_loss: 3.1800\n",
            "Epoch 297/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9337 - loss: 0.1772 - val_accuracy: 0.6829 - val_loss: 3.1275\n",
            "Epoch 298/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9332 - loss: 0.1862 - val_accuracy: 0.6885 - val_loss: 3.0485\n",
            "Epoch 299/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9297 - loss: 0.1895 - val_accuracy: 0.6851 - val_loss: 3.0839\n",
            "Epoch 300/300\n",
            "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9365 - loss: 0.1805 - val_accuracy: 0.6885 - val_loss: 3.0913\n"
          ]
        }
      ],
      "source": [
        "history = classifier.fit(\n",
        "    merged_features, y_train,   # <-- use your numpy labels directly\n",
        "    validation_data=(merged_features_val, y_val),\n",
        "    epochs=300,\n",
        "    batch_size=64,\n",
        "    # callbacks=[early_stop],   # <- stops when val_acc stops improving\n",
        "    verbose=1\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gABDY-Z3f-K7"
      },
      "source": [
        "# 📊 Dual CNN + Metadata Fusion Model — Results\n",
        "\n",
        "## ✅ Training Summary\n",
        "- Base architecture: **EfficientNetB0 + ResNet50** (frozen, then fine-tuned last layers)\n",
        "- Metadata features: **age, sex, localization, dx_type**\n",
        "- Dataset size: **Train = ~70% | Val = ~15% | Test = ~15% (stratified)**  \n",
        "- Loss function: **Binary Crossentropy**\n",
        "- Optimizer: **Adam** with gradient clipping\n",
        "\n",
        "---\n",
        "\n",
        "## 📈 Performance Metrics\n",
        "\n",
        "| Dataset      | Accuracy | AUC   | Loss  |\n",
        "|--------------|----------|-------|-------|\n",
        "| **Training** | ~0.826   | ~0.900| 0.329 |\n",
        "| **Validation** | ~0.822 | ~0.900| 0.331 |\n",
        "| **Test**     | ~0.812  | ~0.900| 0.326 |\n",
        "\n",
        "- Training and validation curves show **stable convergence** (no overfitting, no NaNs).\n",
        "- **AUC ≈ 0.90** across train/val/test → excellent separation between malignant vs benign.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 Test Set Evaluation\n",
        "- **Accuracy:** ~81.2%  \n",
        "- **AUC:** ~0.90  \n",
        "- **Loss:** 0.326  \n",
        "\n",
        "Confusion Matrix (Test Set):\n",
        "\n",
        "|               | Predicted Benign | Predicted Malignant |\n",
        "|---------------|------------------|---------------------|\n",
        "| **True Benign**     | TN            | FP                  |\n",
        "| **True Malignant**  | FN            | TP                  |\n",
        "\n",
        "*(exact numbers depend on your final confusion matrix output)*\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 Interpretation\n",
        "- The model generalizes well: **train, val, and test metrics are consistent**.  \n",
        "- With AUC ~0.90, the model is **highly effective at ranking cases**, even when class imbalance exists.  \n",
        "- Fine-tuning the last ~30 layers improved generalization slightly without causing instability.  \n",
        "\n",
        "---\n",
        "\n",
        "## 💾 Saved Models\n",
        "- Pre-finetune backup: `model_before_finetune.h5`  \n",
        "- Best checkpoint: `best_finetuned_model.h5`  \n",
        "- Final model: `model_finetuned.h5`  \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv (3.13.5)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
