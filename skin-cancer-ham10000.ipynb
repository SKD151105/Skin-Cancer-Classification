{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-17T16:43:16.628587Z",
     "iopub.status.busy": "2025-08-17T16:43:16.628262Z",
     "iopub.status.idle": "2025-08-17T16:43:17.147822Z",
     "shell.execute_reply": "2025-08-17T16:43:17.147162Z",
     "shell.execute_reply.started": "2025-08-17T16:43:16.628563Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/ham1000-segmentation-and-classification\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"surajghuwalewala/ham1000-segmentation-and-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T16:43:17.149385Z",
     "iopub.status.busy": "2025-08-17T16:43:17.149181Z",
     "iopub.status.idle": "2025-08-17T16:43:21.101198Z",
     "shell.execute_reply": "2025-08-17T16:43:21.100437Z",
     "shell.execute_reply.started": "2025-08-17T16:43:17.149368Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T16:43:21.103142Z",
     "iopub.status.busy": "2025-08-17T16:43:21.102439Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from CSV...\n",
      "Extracted labels with shape: (10015, 6)\n",
      "\n",
      "Starting image preprocessing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6673/10015 [11:22<05:11, 10.72it/s]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===================================================================\n",
    "# --- 1. Configuration ---\n",
    "# ===================================================================\n",
    "IMAGE_DIR = path+'/images'\n",
    "MASK_DIR = path+'/masks'\n",
    "CSV_PATH = path+'/GroundTruth.csv'\n",
    "\n",
    "IMAGE_ID_COLUMN = 'image'  \n",
    "LABEL_COLUMNS = ['MEL', 'NV', 'BCC','AKIEC','BKL','DF'] \n",
    "TARGET_SIZE = (224, 224)\n",
    "\n",
    "# ===================================================================\n",
    "# --- 2. Preprocessing Functions ---\n",
    "# ===================================================================\n",
    "def remove_hair(image):\n",
    "    \"\"\"Removes hair from a skin image using morphological operations.\"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15)) #15*15 kernel\n",
    "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel) #using blackhat morphology for hair detection\n",
    "    _, hair_mask = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)#hair masked over intensity 10\n",
    "    inpainted_image = cv2.inpaint(image, hair_mask, 3, cv2.INPAINT_TELEA)#inpaint the mask\n",
    "    return inpainted_image\n",
    "\n",
    "def preprocess_for_cnn(image_path, mask_path, target_size):\n",
    "    \"\"\"Full preprocessing pipeline for one image.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if image is None or mask is None:\n",
    "        raise ValueError(\"Image or mask not found.\")\n",
    "\n",
    "    # Hair removal\n",
    "    image_no_hair = remove_hair(image)\n",
    "\n",
    "    # Binary mask\n",
    "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Apply mask\n",
    "    masked_image = cv2.bitwise_and(image_no_hair, image_no_hair, mask=binary_mask)\n",
    "\n",
    "    # Crop to ROI (if mask is valid)\n",
    "    if cv2.countNonZero(binary_mask) > 0:\n",
    "        x, y, w, h = cv2.boundingRect(binary_mask)\n",
    "        cropped_image = masked_image[y:y+h, x:x+w]\n",
    "    else:\n",
    "        cropped_image = image_no_hair  # fallback: use full image\n",
    "\n",
    "    # Resize + normalize\n",
    "    resized_image = cv2.resize(cropped_image, target_size)\n",
    "    normalized_image = resized_image.astype(np.float32) / 255.0\n",
    "\n",
    "    return normalized_image\n",
    "\n",
    "# ===================================================================\n",
    "# --- 3. Data Loading ---\n",
    "# ===================================================================\n",
    "print(\"Loading data from CSV...\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Add file paths\n",
    "def find_image_path(img_id):\n",
    "    for ext in ['.jpg', '.png', '.jpeg']:\n",
    "        path = os.path.join(IMAGE_DIR, img_id + ext)\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "def find_mask_path(img_id):\n",
    "    for ext in ['.png', '.jpg']:\n",
    "        path = os.path.join(MASK_DIR, img_id + '_segmentation' + ext)\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "\n",
    "df['image_path'] = df[IMAGE_ID_COLUMN].apply(find_image_path)\n",
    "df['mask_path'] = df[IMAGE_ID_COLUMN].apply(find_mask_path)\n",
    "\n",
    "# Extract labels\n",
    "all_labels = df[LABEL_COLUMNS].to_numpy()\n",
    "print(f\"Extracted labels with shape: {all_labels.shape}\")\n",
    "\n",
    "# ===================================================================\n",
    "# --- 4. Preprocess Images ---\n",
    "# ===================================================================\n",
    "processed_images = []\n",
    "valid_indices = []\n",
    "\n",
    "print(\"\\nStarting image preprocessing...\")\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    try:\n",
    "        if row['image_path'] and row['mask_path']:\n",
    "            processed_img = preprocess_for_cnn(row['image_path'], row['mask_path'], TARGET_SIZE)\n",
    "            processed_images.append(processed_img)\n",
    "            valid_indices.append(index)\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {index} ({row[IMAGE_ID_COLUMN]}): {e}\")\n",
    "\n",
    "# Convert to arrays\n",
    "X = np.array(processed_images, dtype=np.float32)\n",
    "y = all_labels[valid_indices]\n",
    "\n",
    "print(\"\\nProcessing Complete\")\n",
    "print(f\"Processed {len(X)} images.\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(df[['image', 'image_path', 'mask_path']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=12, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-17T14:12:29.825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "# ==============================\n",
    "# 1. Define CNN Architecture\n",
    "# ==============================\n",
    "\n",
    "model = Sequential([\n",
    "    # Block 1\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Block 2\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Block 3\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    # Flatten + Dense\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    # Output Layer\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# ==============================\n",
    "# 2. Compile Model\n",
    "# ==============================\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-17T14:12:29.825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1370616,
     "isSourceIdPinned": false,
     "sourceId": 2275763,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
